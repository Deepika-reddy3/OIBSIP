import pandas as pd,,,,,
import numpy as np,,,,,
import seaborn as sns,,,,,
import matplotlib.pyplot as plt,,,,,
ds=pd.read_csv('Advertising.csv'),,,,,
ds,,,,,
Unnamed: 0,,TV,Radio,Newspaper,Sales
0,1,230.1,37.8,69.2,22.1
1,2,44.5,39.3,45.1,10.4
2,3,17.2,45.9,69.3,9.3
3,4,151.5,41.3,58.5,18.5
4,5,180.8,10.8,58.4,12.9
...,...,...,...,...,...
195,196,38.2,3.7,13.8,7.6
196,197,94.2,4.9,8.1,9.7
197,198,177,9.3,6.4,12.8
198,199,283.6,42,66.2,25.5
199,200,232.1,8.6,8.7,13.4
200 rows × 5 columns,,,,,
ds.head(10),,,,,
Unnamed: 0,,TV,Radio,Newspaper,Sales
0,1,230.1,37.8,69.2,22.1
1,2,44.5,39.3,45.1,10.4
2,3,17.2,45.9,69.3,9.3
3,4,151.5,41.3,58.5,18.5
4,5,180.8,10.8,58.4,12.9
5,6,8.7,48.9,75,7.2
6,7,57.5,32.8,23.5,11.8
7,8,120.2,19.6,11.6,13.2
8,9,8.6,2.1,1,4.8
9,10,199.8,2.6,21.2,10.6
ds.tail(10),,,,,
Unnamed: 0,,TV,Radio,Newspaper,Sales
190,191,39.5,41.1,5.8,10.8
191,192,75.5,10.8,6,9.9
192,193,17.2,4.1,31.6,5.9
193,194,166.8,42,3.6,19.6
194,195,149.7,35.6,6,17.3
195,196,38.2,3.7,13.8,7.6
196,197,94.2,4.9,8.1,9.7
197,198,177,9.3,6.4,12.8
198,199,283.6,42,66.2,25.5
199,200,232.1,8.6,8.7,13.4
ds.info(),,,,,
,,,,,,
"RangeIndex: 200 entries, 0 to 199",,,,,,
Data columns (total 5 columns):,,,,,,
 # Column Non-Null Count Dtype ,,,,,,
--- ------ -------------- ----- ,,,,,,
 0 Unnamed: 0 200 non-null int64 ,,,,,,
 1 TV 200 non-null float64,,,,,,
 2 Radio 200 non-null float64,,,,,,
 3 Newspaper 200 non-null float64,,,,,,
 4 Sales 200 non-null float64,,,,,,
"dtypes: float64(4), int64(1)",,,,,,
memory usage: 7.9 KB,,,,,,
ds.describe(),,,,,,
,Unnamed: 0,,TV,Radio,Newspaper,Sales
count,200,200,200,200,200,
mean,100.5,147.0425,23.264,30.554,14.0225,
std,57.879185,85.854236,14.846809,21.778621,5.217457,
min,1,0.7,0,0.3,1.6,
25%,50.75,74.375,9.975,12.75,10.375,
50%,100.5,149.75,22.9,25.75,12.9,
75%,150.25,218.825,36.525,45.1,17.4,
max,200,296.4,49.6,114,27,
"a=ds.iloc[:,0:-1]",,,,,,
a,,,,,,
Unnamed: 0,,TV,Radio,Newspaper,,
0,1,230.1,37.8,69.2,,
1,2,44.5,39.3,45.1,,
2,3,17.2,45.9,69.3,,
3,4,151.5,41.3,58.5,,
4,5,180.8,10.8,58.4,,
...,...,...,...,...,,
195,196,38.2,3.7,13.8,,
196,197,94.2,4.9,8.1,,
197,198,177,9.3,6.4,,
198,199,283.6,42,66.2,,
199,200,232.1,8.6,8.7,,
200 rows × 4 columns,,,,,,
"b=ds.iloc[:,-1]",,,,,,
b,,,,,,
0 22.1,,,,,,
1 10.4,,,,,,
2 9.3,,,,,,
3 18.5,,,,,,
4 12.9,,,,,,
, ... ,,,,,
195 7.6,,,,,,
196 9.7,,,,,,
197 12.8,,,,,,
198 25.5,,,,,,
199 13.4,,,,,,
"Name: Sales, Length: 200, dtype: float64",,,,,,
"a.iloc[:,0]",,,,,,
0 1,,,,,,
1 2,,,,,,
2 3,,,,,,
3 4,,,,,,
4 5,,,,,,
, ... ,,,,,
195 196,,,,,,
196 197,,,,,,
197 198,,,,,,
198 199,,,,,,
199 200,,,,,,
"Name: Unnamed: 0, Length: 200, dtype: int64",,,,,,
ds.head(10),,,,,,
Unnamed: 0,,TV,Radio,Newspaper,Sales,
0,1,230.1,37.8,69.2,22.1,
1,2,44.5,39.3,45.1,10.4,
2,3,17.2,45.9,69.3,9.3,
3,4,151.5,41.3,58.5,18.5,
4,5,180.8,10.8,58.4,12.9,
5,6,8.7,48.9,75,7.2,
6,7,57.5,32.8,23.5,11.8,
7,8,120.2,19.6,11.6,13.2,
8,9,8.6,2.1,1,4.8,
9,10,199.8,2.6,21.2,10.6,
ds.corr(),,,,,,
,Unnamed: 0,,TV,Radio,Newspaper,Sales
Unnamed: 0,,1,0.017715,-0.110680,-0.154944,-0.051616
TV,,0.017715,1,0.054809,0.056648,0.782224
Radio,,-0.110680,0.054809,1,0.354104,0.576223
Newspaper,,-0.154944,0.056648,0.354104,1,0.228299
Sales,,-0.051616,0.782224,0.576223,0.228299,1
sns.pairplot(data=ds),,,,,,
plt.show(),,,,,,
"plt.figure(figsize=(20,6))"
"sns.heatmap(ds.corr(),annot=True,cmap=""summer"")"
"plt.title(""Coorelation among the features"",fontweight=""black"",fontsize=20,pad=20)"
plt.show()
"plt.figure(figsize=(15,6))"
"plt.subplot(1,2,1)"
"sns.histplot(ds[""Sales""],color=""red"",kde=True)"
"plt.title(""Sales feature distribution"",fontweight=""black"",pad=20,fontsize=20)"
plt.show()
from sklearn.model_selection import train_test_split,,,,
"a_train,a_test,b_train,b_test=train_test_split(a,b,test_size=0.2,random_state=3)",,,,
a_train,,,,
Unnamed: 0,,TV,Radio,Newspaper
156,157,93.9,43.5,50.5
115,116,75.1,35,52.7
155,156,4.1,11.6,5.7
15,16,195.4,47.7,52.9
61,62,261.3,42.7,54.7
...,...,...,...,...
0,1,230.1,37.8,69.2
184,185,253.8,21.3,30
131,132,265.2,2.9,43
152,153,197.6,23.3,14.2
106,107,25,11,29.7
160 rows × 4 columns,,,,
a_test,,,,
Unnamed: 0,,TV,Radio,Newspaper
40,41,202.5,22.3,31.6
51,52,100.4,9.6,3.6
139,140,184.9,43.9,1.7
197,198,177,9.3,6.4
170,171,50,11.6,18.4
82,83,75.3,20.3,32.5
183,184,287.6,43,71.8
46,47,89.7,9.9,35.7
70,71,199.1,30.6,38.7
100,101,222.4,4.3,49.8
179,180,165.6,10,17.6
83,84,68.4,44.5,35.6
25,26,262.9,3.5,19.5
190,191,39.5,41.1,5.8
159,160,131.7,18.4,34.6
173,174,168.4,7.1,12.8
95,96,163.3,31.6,52.9
3,4,151.5,41.3,58.5
41,42,177,33.4,38.7
58,59,210.8,49.6,37.7
14,15,204.1,32.9,46
143,144,104.6,5.7,34.4
12,13,23.8,35.1,65.9
6,7,57.5,32.8,23.5
182,183,56.2,5.7,29.7
161,162,85.7,35.8,49.3
128,129,220.3,49,3.2
122,123,224,2.4,15.6
101,102,296.4,36.3,100.9
86,87,76.3,27.5,16
64,65,131.1,42.8,28.9
47,48,239.9,41.5,18.5
158,159,11.7,36.9,45.2
34,35,95.7,1.4,7.4
38,39,43.1,26.7,35.1
196,197,94.2,4.9,8.1
4,5,180.8,10.8,58.4
72,73,26.8,33,19.3
67,68,139.3,14.5,10.2
145,146,140.3,1.9,9
b_train,,,,
156 15.3,,,,
115 12.6,,,,
155 3.2,,,,
15 22.4,,,,
61 24.2,,,,
 ... ,,,,
0 22.1,,,,
184 17.6,,,,
131 12.7,,,,
152 16.6,,,,
106 7.2,,,,
"Name: Sales, Length: 160, dtype: float64",,,,
b_test,,,,
40 16.6,
51 10.7,
139 20.7,
197 12.8,
170 8.4,
82 11.3,
183 26.2,
46 10.6,
70 18.3,
100 11.7,
179 12.6,
83 13.6,
25 12.0,
190 10.8,
159 12.9,
173 11.7,
95 16.9,
3 18.5,
41 17.1,
58 23.8,
14 19.0,
143 10.4,
12 9.2,
6 11.8,
182 8.7,
161 13.3,
128 24.7,
122 11.6,
101 23.8,
86 12.0,
64 18.0,
47 23.2,
158 7.3,
34 9.5,
38 10.1,
196 9.7,
4 12.9,
72 8.8,
67 13.4,
145 10.3,
"Name: Sales, dtype: float64",
from sklearn.preprocessing import StandardScaler,
ss=StandardScaler(),
a_train_scale=ss.fit_transform(a_train),
a_test_scale=ss.fit_transform(a_test),
from sklearn.linear_model import LinearRegression,
ls=LinearRegression(),
"ls.fit(a_train_scale,b_train)",
▾ LinearRe,gression
LinearRegr,ession()
b_prediction=ls.predict(a_test_scale),
b_prediction,
"array([17.09361159, 9.41048089, 19.80587243, 13.3008359 , 6.98124657,",
," 9.9392531 , 25.13627535, 8.92756703, 18.33921532, 14.97368543,"
" 12.84335278, 13.79529823, 17.03057874, 11.5382694 , 12.5390863 ,",
" 12.48763233, 16.59882872, 17.75335623, 17.67869696, 22.28608017,",
" 19.06497561, 8.89664676, 9.87630366, 11.23477943, 6.28119552,",
" 13.13846051, 22.59041879, 14.67569342, 24.53837344, 11.22954428,",
" 16.84605452, 22.41399974, 9.39233796, 7.74931761, 9.38561106,",
," 8.13061526, 13.99103686, 9.57135711, 12.32601414, 10.10804088])"
b_test,
40 16.6
51 10.7
139 20.7
197 12.8
170 8.4
82 11.3
183 26.2
46 10.6
70 18.3
100 11.7
179 12.6
83 13.6
25 12.0
190 10.8
159 12.9
173 11.7
95 16.9
3 18.5
41 17.1
58 23.8
14 19.0
143 10.4
12 9.2
6 11.8
182 8.7
161 13.3
128 24.7
122 11.6
101 23.8
86 12.0
64 18.0
47 23.2
158 7.3
34 9.5
38 10.1
196 9.7
4 12.9
72 8.8
67 13.4
145 10.3
"Name: Sales, dtype: float64"
"plt.scatter(b_test,b_prediction,c='b',label='prediction',marker='X')"
"plt.scatter(b_test,b_test,c='r',label='True',marker='o')"
plt.title('True vs predicted values')
plt.legend()
plt.show()
from sklearn.metrics import mean_squared_error
"me=mean_squared_error(b_test,b_prediction)"
me
2.268779527
from sklearn.metrics import mean_absolute_error
"me=mean_absolute_error(b_test,b_prediction)"
me
1.144562736
from sklearn.metrics import r2_score
"r2=r2_score(b_test,b_prediction)"
r2
0.909236997
Loading [MathJax]/jax/output/CommonHTML/fonts/TeX/fontdata.js
